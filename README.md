This is a package for mapping post-translational modifications (obtained from Proteomescout) to the gene, transcript, and exon that codes for each PTM. 

# Setting up your environment

Currently, there is no setup.py file or pip/conda installable as this is a work in progress, so I have been working in a development environment.

```
git clone https://github.com/NaegleLab/ExonPTMapper
conda create -n splicing
conda develop ExonPTMapper  #need conda-build installed to do this
```

Need to add .yaml and requirements.txt to include the additional dependencies required for package (mostly the usual suspects, pandas, numpy, etc.)

## Setting up config.py

To configure ExonPTMapper, need to indicate to the package where your data files will be located, as well as where the api is located. Open config.py and change the variables: 
1. 'api_dir': location where API is stored (not needed once it is pip installable)
2. 'ps_data_dir': directory which contains or will contain the ProteomeScout data files
2. 'source_data_dir': where data from various databases (like ensembl) is saved
3. 'processed_data_dir': directory which will contain processed created data files

Config.py performs several roles:
1. Loads ProteomeScoutAPI
2. Processes the ensemble to uniprot mapping file into a usable pandas dataframe (called 'translator')
3. Loads the 'available_transcripts.json' file, if it has been generated by processing.py previously. This file contains a list that indicates which transcripts have amino acid sequences matching those of their corresponding uniprot record.

## Downloading the necessary data

Eventually, may want to streamline this (possible to download files automatically?), but for not several files need to be downloaded, either from ensemble or proteomescout.

### ProteomeScout Data

To download the data that the proteomescout API will work with, follow the below steps:
1. Navigate to [ProteomeScout](https://proteomescout.wustl.edu/). Will need to update once proteomescout is off WashU servers.
2. Go to 'Downloads'
3. Download the zip file for mammalian PTMs
4. Extract contents of zip file to 'ps_data_dir'

### Ensembl Data

From ensembl, we need exon sequences, exon ranks, coding sequences, and the ensembl to uniprot mapping file. To download use Biomart:

1. Go to [ensembl](https://useast.ensembl.org/index.html)
2. Navigate to biomart tab
3. Choose Ensembl Genes 107, then Human genes
4. Under 'Filters', go the gene tab. Check both 'Gene type' and 'Transcript type' and select 'protein_coding'.
5. Navigate to attributes
	1. For exon information, click sequences -> Exon sequences. Under header information, check 'Exon stable ID' and "Exon rank". Call this file 'exon_sequences.fasta.gz'.
	2. For coding sequences, click sequences -> Coding sequences. Call this file 'coding_sequences.fasta.gz'
	3. For meta information, click attributes and select: . Call this info 'meta_info.csv.gz'
	4. For translator file, click features and select: . Call this file ______
6. Click 'Results' (upper left corner)
7. Download compressed file and save in processed_data_dir

## Processing Ensembl Info

To process exons file, first import packages and load data
```
#load sequence data
exon_sequences = config.processEnsemblFasta(config.source_data_dir+'exon_sequences.fasta.gz', id_col = 'Exon stable ID', seq_col = 'Exon Sequence')
coding_sequences = config.processEnsemblFasta(config.source_data_dir+'coding_sequences.fasta.gz', id_col = 'Transcript stable ID', seq_col = 'Coding Sequence')

#load and process meta data
meta = pd.read_csv(config.source_data_dir + '/meta_info.csv.gz', compression = 'gzip')
genes = meta[['Gene name','Transcript stable ID', 'Gene start (bp)','Gene end (bp)', 'Chromosome/scaffold name']]
genes.index = meta['Gene stable ID']
#get rid of excess due to exon ids
genes = genes.drop_duplicates()
#collapse each gene into a single a row
genes['Protein coding transcripts'] = genes['Transcript stable ID'].groupby('Gene stable ID').apply(','.join)
genes = genes.drop('Transcript stable ID', axis = 1)
genes = genes.drop_duplicates()
#make transcript dataframe
transcripts = meta[['Gene stable ID', 'Transcript start (bp)','Transcript end (bp)', 'Transcription start site (TSS)','Transcript length (including UTRs and CDS)', 'CDS Length']]
transcripts.index = meta['Transcript stable ID']
transcripts = transcripts.drop_duplicates()

#extract exon info
exons = meta[['Gene stable ID', 'Transcript stable ID', 'Exon stable ID', 'Constitutive exon', 'Exon region start (bp)', 'Exon region end (bp)', 'Exon rank in transcript', 'Genomic coding start', 'Genomic coding end']]
exons = exons.rename({'Exon region start (bp)':'Exon Start (Gene)', 'Exon region end (bp)':'Exon End (Gene)'}, axis = 1)

TRIFID = pd.read_csv(config.source_data_dir + 'TRIFID.txt',sep = '\t')
```

Then, simply run the various processing functions
```
exons = processing.processExons(exons, exon_sequences)
transcripts = processing.processTranscripts(transcripts, coding_sequences, exons, TRIFID = TRIFID)
proteins = processing.getProteinInfo()
```
Get all transcript-specific exon sequences
```
aa_seq_ragged, aa_seq_nr, exon_prot_starts, exon_prot_ends = processing.getAllExonSequences(exons, transcripts)
exons['Exon Start (Protein)'] = exon_prot_starts
exons['Exon End (Protein)'] = exon_prot_ends
exons['Exon AA Seq (Ragged)'] = aa_seq_ragged
exons['Exon AA Seq (Full Codon)'] = aa_seq_nr
```


Save each data file
```
exons.to_csv(config.processed_data_dir + 'exons.csv')
transcripts.to_csv(config.processed_data_dir + 'transcripts.csv')
genes.to_csv(config.processed_data_dir + 'genes.csv')
proteins.to_csv(config.processed_data_dir + 'proteins.csv')
```

## Map PTMs to Exons

The next step is to integrate PTM level information from proteomeScout and the data files processed from the previous step. In order to do this, we first need to check which transcripts from Ensembl match the information found in ProteomeScout (do the amino acid sequences match?). These will be the transcripts that we predominantly work with:
```
processing.getMatchedTranscripts(transcripts, update = True)
``` 
The above will automatically save the list of available transcripts in the processed data directory.

Next, load data:
```
from ExonPTMapper.newdata_processing import mapping, config

mapper = mapping.load_PTMmapper()
```

Next, find PTMs related to available transcripts, then map the PTM to exons/genes:
```
mapper.findAllPTMs()
mapper.mapPTMs_all()
```

Also run additional functions to further annotate PTMs
```
mapper.getAllTrypticFragments()
mapper.getAllFlankingSeqs()
mapper.findAllinDomains()
mapper.boundary_analysis()
```

Save ptm_info
```
mapper.ptm_info.to_csv(config.processed_data_dir + 'ptm_info.csv')
```
