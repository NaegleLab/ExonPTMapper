This is a package for mapping post-translational modifications (obtained from Proteomescout) to the gene, transcript, and exon that codes for each PTM. 

## Generating data files

### Setting up your environment

Currently, there is no setup.py file or pip/conda installable as this is a work in progress, so I have been working in a development environment.

```
git clone https://github.com/NaegleLab/ExonPTMapper
conda create -n splicing
conda develop ExonPTMapper  #need conda-build installed to do this
```

Need to add .yaml and requirements.txt to include the additional dependencies required for package (mostly the usual suspects, pandas, numpy, etc.)

### Setting up config.py

To configure ExonPTMapper, need to indicate to the package where your data files will be located, as well as where the api is located. Open config.py and change the variables: 
1. 'api_dir': location where API is stored (not needed once it is pip installable)
2. 'ps_data_dir': directory which contains or will contain the ProteomeScout data files
2. 'source_data_dir': where data from various databases (like ensembl) is saved
3. 'processed_data_dir': directory which will contain processed created data files

Config.py performs several roles:
1. Loads ProteomeScoutAPI
2. Processes the ensemble to uniprot mapping file into a usable pandas dataframe (called 'translator')
3. Loads the 'available_transcripts.json' file, if it has been generated by processing.py previously. This file contains a list that indicates which transcripts have amino acid sequences matching those of their corresponding uniprot record.

### Downloading the necessary data

Eventually, may want to streamline this (possible to download files automatically?), but for not several files need to be downloaded, either from ensemble or proteomescout.

#### ProteomeScout Data

To download the data that the proteomescout API will work with, follow the below steps:
1. Navigate to [ProteomeScout](https://proteomescout.wustl.edu/). Will need to update once proteomescout is off WashU servers.
2. Go to 'Downloads'
3. Download the zip file for mammalian PTMs
4. Extract contents of zip file to 'ps_data_dir'

#### Ensembl Data

From ensembl, we need exon sequences, exon ranks, coding sequences, and the ensembl to uniprot mapping file. To download use Biomart:

1. Go to [ensembl](https://useast.ensembl.org/index.html)
2. Navigate to biomart tab
3. Choose Ensembl Genes 107, then Human genes
4. Under 'Filters', go the gene tab. Check both 'Gene type' and 'Transcript type' and select 'protein_coding'.
5. Navigate to attributes
	1. For exon information, click sequences -> Exon sequences. Under header information, check 'Exon stable ID' and "Exon rank". Call this file 'exon_sequences.fasta.gz'.
	2. For coding sequences, click sequences -> Coding sequences. Call this file 'coding_sequences.fasta.gz'
6. Click 'Results' (upper left corner)
7. Download compressed file and save in processed_data_dir

## Mapping and Projecting PTMs onto Alternative Transcripts

Loading in data and running the entire mapping pipeline only requires the use of one master function:
```
from ExonPTMapper import mapping

mapper = mapping.run_mapping()
```
This will load any data found within the processed_data_dir indicated in the config file. Based on the available information, it will start the mapping/projection procedure at a point is not redundant (i.e. it will not calculate/obtain any information that already exists). If you wish to start the process from scratch, you may set restart = True.

The pipeline will also automatically save new data files in the processed_data_dir.


